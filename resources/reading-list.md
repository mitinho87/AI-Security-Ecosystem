# AI/ML Security Reading List

Curated resources for learning about AI/ML security, organized by topic and skill level.

## üìö Getting Started

### Essential Reading
- **[OWASP LLM Top 10](https://owasp.org/www-project-top-10-for-large-language-model-applications/)** - Start here for GenAI security fundamentals
- **[Google's ML Security Overview](https://developers.google.com/machine-learning/guides/security)** - Comprehensive introduction
- **[Microsoft's AI Security Best Practices](https://www.microsoft.com/en-us/security/blog/topic/ai-security/)** - Practical guidance

### Online Courses (That I've Completed)
- **[Attacking AI - Arcanum Information Security](https://www.arcanuminfosec.com/)** - Offensive AI security training
- **[PortSwigger Web Security Academy - LLM Attacks](https://portswigger.net/web-security/llm-attacks)** - Hands-on labs
- **[SANS SEC540](https://www.sans.org/cyber-security-courses/cloud-security-and-devsecops-automation/)** - Cloud/DevSecOps fundamentals

## üéØ By Topic

### Prompt Injection
- [Prompt Injection Taxonomy](https://github.com/jthack/PIPE) - Comprehensive attack patterns
- [Simon Willison's Prompt Injection Series](https://simonwillison.net/series/prompt-injection/) - Excellent blog series
- [Adversarial Prompts](https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-adversarial.md) - Attack examples

### RAG Security
- [Vector Database Security](https://weaviate.io/blog/security-best-practices) - Securing vector stores
- [RAG Security Considerations](https://arxiv.org/abs/2402.04031) - Academic research
- [Document Poisoning in RAG](https://arxiv.org/abs/2310.04451) - Attack research

### Agent & MCP Security
- [Model Context Protocol Spec](https://spec.modelcontextprotocol.io/) - Official documentation
- [Agent Security Risks](https://arxiv.org/abs/2308.04132) - Research paper
- [Multi-Agent System Security](https://arxiv.org/abs/2311.08536) - Academic overview

### Data Privacy & Model Security
- [Differential Privacy for ML](https://github.com/google/differential-privacy) - Google's library
- [Model Extraction Attacks](https://arxiv.org/abs/1609.02943) - Foundational paper
- [Training Data Extraction](https://arxiv.org/abs/2012.07805) - Research on memorization

## üîß Practical Resources

### Tools & Frameworks
- **[Garak](https://github.com/leondz/garak)** - LLM vulnerability scanner
- **[PyRIT](https://github.com/Azure/PyRIT)** - Python Risk Identification Toolkit (Microsoft)
- **[NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails)** - Programmable guardrails
- **[LangChain Security](https://python.langchain.com/docs/security)** - Framework security docs
- **[MLflow](https://mlflow.org/)** - ML lifecycle management
- **[DVC](https://dvc.org/)** - Data version control

### Testing & Validation
- **[OWASP ML Testing Guide](https://owasp.org/www-project-machine-learning-security-top-10/)** - Testing methodologies
- **[Adversarial Robustness Toolbox](https://github.com/Trusted-AI/adversarial-robustness-toolbox)** - IBM's testing toolkit
- **[Promptfoo](https://www.promptfoo.dev/)** - LLM testing framework

## üì∞ Blogs & News

### Must-Follow Blogs
- [Simon Willison's Weblog](https://simonwillison.net/) - AI security insights
- [Trail of Bits AI Security](https://blog.trailofbits.com/category/ai/) - Security research
- [Google AI Safety Blog](https://ai.google/safety/) - Latest research
- [Anthropic Research](https://www.anthropic.com/research) - LLM safety research

### News Sources
- [The Gradient](https://thegradient.pub/) - AI research explained
- [Import AI](https://importai.substack.com/) - Weekly AI newsletter
- [TLDR AI](https://tldr.tech/ai) - Daily AI news

## üìñ Academic Papers

### Foundational
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Transformer architecture
- [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) - GPT-3 paper
- [Constitutional AI](https://arxiv.org/abs/2212.08073) - AI alignment

### Security-Focused
- [Universal and Transferable Adversarial Attacks](https://arxiv.org/abs/1707.02967)
- [Extracting Training Data from LLMs](https://arxiv.org/abs/2012.07805)
- [Prompt Injection Attacks](https://arxiv.org/abs/2302.12173)
- [Jailbreaking ChatGPT](https://arxiv.org/abs/2307.02483)

## üéì Advanced Topics

### ML Supply Chain Security
- [Securing the ML Pipeline](https://www.microsoft.com/en-us/research/publication/securing-the-machine-learning-pipeline/)
- [SLSA for ML](https://slsa.dev/) - Supply chain security framework
- [ML Model Cards](https://modelcards.withgoogle.com/) - Transparency documentation

### Compliance & Governance
- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
- [EU AI Act Overview](https://artificialintelligenceact.eu/)
- [IEEE Ethics in AI](https://standards.ieee.org/industry-connections/ec/autonomous-systems/)

## üé• Videos & Talks

### Conference Talks
- **DEF CON AI Village** - Annual AI security talks
- **Black Hat AI Security Track** - Enterprise security focus
- **OWASP AppSec** - Application security with ML

### YouTube Channels
- [Two Minute Papers](https://www.youtube.com/@TwoMinutePapers) - AI research simplified
- [Yannic Kilcher](https://www.youtube.com/@YannicKilcher) - Paper explanations
- [AI Explained](https://www.youtube.com/@aiexplained-official) - LLM news and analysis

## üèÜ Certifications & Training

### Relevant Certifications
- **CISSP** - General security foundation (I have this)
- **AWS/Azure ML Specialty** - Cloud ML security
- **CSSLP** - Secure software lifecycle

### Specialized Training
- **Offensive AI Security** - Arcanum, Wild West Hackin' Fest
- **LLM Security** - PortSwigger, PentesterLab
- **MLSecOps** - SANS, Linux Foundation

## üìö Books

### AI Security
- *Adversarial Machine Learning* - Joseph, Nelson
- *The Alignment Problem* - Brian Christian
- *AI Safety* - Stuart Russell

### General ML
- *Hands-On Machine Learning* - Aur√©lien G√©ron
- *Deep Learning* - Goodfellow, Bengio, Courville
- *The Hundred-Page Machine Learning Book* - Andriy Burkov

## üîó Communities

### Online Communities
- [r/MachineLearning Security](https://www.reddit.com/r/MachineLearning/) - Reddit discussions
- [OWASP ML Security Project](https://owasp.org/www-project-machine-learning-security-top-10/) - Open community
- [AI Safety Discussion](https://www.aisafety.com/) - Safety-focused community

### Professional Groups
- **ISACA AI Audit & Security**
- **ISC2 AI Security SIG**
- **IEEE AI & Ethics**

---

*This list is continuously updated as I discover new resources.*

*Last Updated: February 2026*
